{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d449185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'..')\n",
    "import pandas as pd\n",
    "from lib_template.settings import DATA_DIR\n",
    "import glob\n",
    "import pathlib\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "\n",
    "def _process_data(DATA_DIR, temporary_dir= \"temporary\", processed_dir= \"persistent\", file_type= \"csv\"):\n",
    "    file_list = glob.glob(f'{DATA_DIR}\\\\{temporary_dir}\\\\**', recursive=True)\n",
    "    file_of_matched_type = [file for file in file_list if file.endswith(f\".{file_type}\")]\n",
    "    matched_dfs = [pd.read_csv(file) for file in file_of_matched_type]\n",
    "    file_hash = [joblib.hash(df, hash_name='sha1') for df in matched_dfs]\n",
    "    file_names = [str(pathlib.Path(f).name).replace(f\".{file_type}\",\"\") for f in file_of_matched_type]\n",
    "    new_files_collector = []\n",
    "    for hash_key, old_file in zip(file_hash,file_of_matched_type):\n",
    "        new_file_name = f\"{hash_key}.{file_type}\"\n",
    "        new_file = pathlib.Path(os.path.join(DATA_DIR, processed_dir, new_file_name))\n",
    "        old_file_path = pathlib.Path(old_file)\n",
    "        if not new_file.is_file():\n",
    "            old_file_path.rename(new_file)\n",
    "        old_file_path.unlink(missing_ok = True)\n",
    "        new_files_collector.append(new_file)\n",
    "    data_lock = dict(zip(file_hash, new_files_collector))\n",
    "    data_name_dict = dict(zip(file_hash, file_names))\n",
    "    return data_lock, data_name_dict\n",
    "\n",
    "\n",
    "def _generate_data_lock(DATA_DIR, data_hash_lock=\"local_data_lock.pickle\", data_name_metadata = \"local_meta_data.pickle\"):\n",
    "    \n",
    "    new_data_lock, data_name_dict = _process_data(DATA_DIR)\n",
    "    data_lock_path = pathlib.Path(os.path.join(DATA_DIR, data_hash_lock))\n",
    "    meta_data_path = pathlib.Path(os.path.join(DATA_DIR, data_name_metadata))\n",
    "    if data_lock_path.is_file():\n",
    "        with open(data_lock_path, 'rb') as handle:\n",
    "            old_data_lock = pickle.load(handle)\n",
    "        if new_data_lock:\n",
    "            data_lock = {**old_data_lock, **new_data_lock}\n",
    "        else:\n",
    "            data_lock = old_data_lock.copy()\n",
    "    else:\n",
    "        data_lock = new_data_lock.copy()\n",
    "    if data_lock:\n",
    "        with open(data_lock_path, 'wb') as handle:\n",
    "            pickle.dump(data_lock, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    return data_lock, data_lock_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "fce4513c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_lock, data_lock_path = _generate_data_lock(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "12f4c2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('C:/Workspace/projects/lib_template/data/local_data_lock.pickle')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lock_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2f19785d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'090ade65772b70f36184e84745715a0d6c277982': WindowsPath('C:/Workspace/projects/lib_template/data/persistent/090ade65772b70f36184e84745715a0d6c277982.csv'),\n",
       " 'c0e894ee39909eb2cc05fd9f597b016a908fcb5d': WindowsPath('C:/Workspace/projects/lib_template/data/persistent/c0e894ee39909eb2cc05fd9f597b016a908fcb5d.csv')}"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "70832e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of files present in persistent folder in blob.\n",
    "# whatever is not matching with the local data_lock file upload that\n",
    "# update the online data lock file\n",
    "\n",
    "\n",
    "# read the file present in presistent folder. extract hash key of each file.\n",
    "# read data lock file in local. check diff, download only the files which are not present in local.\n",
    "# update the local data lock file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46238c74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
